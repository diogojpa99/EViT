{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eCQiB0UWwQZ",
        "outputId": "27df294b-6271-404c-fa1e-03e628ebee07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4znCGMUjQN5",
        "outputId": "a8641075-8ab6-4402-8e60-6cfac336379f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 1)) (1.9.0)\n",
            "Requirement already satisfied: torchvision==0.10.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 2)) (0.10.0)\n",
            "Requirement already satisfied: timm==0.4.12 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 3)) (0.4.12)\n",
            "Requirement already satisfied: tensorboardX==2.4 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 4)) (2.4)\n",
            "Requirement already satisfied: torchprofile==0.0.4 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 5)) (0.0.4)\n",
            "Requirement already satisfied: lmdb==1.2.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 6)) (1.2.1)\n",
            "Requirement already satisfied: pyarrow==5.0.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 7)) (5.0.0)\n",
            "Requirement already satisfied: einops==0.4.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 8)) (0.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.9.0->-r requirements.txt (line 1)) (4.5.0)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision==0.10.0->-r requirements.txt (line 2)) (8.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision==0.10.0->-r requirements.txt (line 2)) (1.22.4)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.9/dist-packages (from tensorboardX==2.4->-r requirements.txt (line 4)) (3.19.6)\n"
          ]
        }
      ],
      "source": [
        "pip install -r new_requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87gq5T4Elk67",
        "outputId": "e09533ac-3d4a-425e-8b72-1df423607051"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "output dir: /content/gdrive/MyDrive/IST/Thesis/Results/train_log/exp_20230317_172323\n",
            "/usr/local/lib/python3.9/dist-packages/torch/distributed/launch.py:163: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
            "  logger.warn(\n",
            "The module torch.distributed.launch is deprecated and going to be removed in future.Migrate to torch.distributed.run\n",
            "*****************************************\n",
            "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
            "*****************************************\n",
            "INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:\n",
            "  entrypoint       : main.py\n",
            "  min_nodes        : 1\n",
            "  max_nodes        : 1\n",
            "  nproc_per_node   : 8\n",
            "  run_id           : none\n",
            "  rdzv_backend     : static\n",
            "  rdzv_endpoint    : 127.0.0.1:29500\n",
            "  rdzv_configs     : {'rank': 0, 'timeout': 900}\n",
            "  max_restarts     : 3\n",
            "  monitor_interval : 5\n",
            "  log_dir          : None\n",
            "  metrics_cfg      : {}\n",
            "\n",
            "INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /tmp/torchelastic_lcpfq5pe/none_fvjexry6\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python3\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group\n",
            "/usr/local/lib/python3.9/dist-packages/torch/distributed/elastic/utils/store.py:52: FutureWarning: This is an experimental API and will be changed in future.\n",
            "  warnings.warn(\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:\n",
            "  restart_count=0\n",
            "  master_addr=127.0.0.1\n",
            "  master_port=29500\n",
            "  group_rank=0\n",
            "  group_world_size=1\n",
            "  local_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
            "  role_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
            "  global_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
            "  role_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]\n",
            "  global_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]\n",
            "\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group\n",
            "INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_lcpfq5pe/none_fvjexry6/attempt_0/0/error.json\n",
            "INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /tmp/torchelastic_lcpfq5pe/none_fvjexry6/attempt_0/1/error.json\n",
            "INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /tmp/torchelastic_lcpfq5pe/none_fvjexry6/attempt_0/2/error.json\n",
            "INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /tmp/torchelastic_lcpfq5pe/none_fvjexry6/attempt_0/3/error.json\n",
            "INFO:torch.distributed.elastic.multiprocessing:Setting worker4 reply file to: /tmp/torchelastic_lcpfq5pe/none_fvjexry6/attempt_0/4/error.json\n",
            "INFO:torch.distributed.elastic.multiprocessing:Setting worker5 reply file to: /tmp/torchelastic_lcpfq5pe/none_fvjexry6/attempt_0/5/error.json\n",
            "INFO:torch.distributed.elastic.multiprocessing:Setting worker6 reply file to: /tmp/torchelastic_lcpfq5pe/none_fvjexry6/attempt_0/6/error.json\n",
            "INFO:torch.distributed.elastic.multiprocessing:Setting worker7 reply file to: /tmp/torchelastic_lcpfq5pe/none_fvjexry6/attempt_0/7/error.json\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Creating model: deit_small_patch16_shrink_base/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "Creating model: deit_small_patch16_shrink_base\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Creating model: deit_small_patch16_shrink_base\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Creating model: deit_small_patch16_shrink_base\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Creating model: deit_small_patch16_shrink_base/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "Creating model: deit_small_patch16_shrink_baseCreating model: deit_small_patch16_shrink_base\n",
            "\n",
            "Creating model: deit_small_patch16_shrink_base\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/deit/deit_small_patch16_224-cd65a155.pth\" to /root/.cache/torch/hub/checkpoints/deit_small_patch16_224-cd65a155.pth\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/deit/deit_small_patch16_224-cd65a155.pth\" to /root/.cache/torch/hub/checkpoints/deit_small_patch16_224-cd65a155.pth\n",
            " 18% 15.4M/84.2M [00:00<00:03, 21.3MB/s]Downloading: \"https://dl.fbaipublicfiles.com/deit/deit_small_patch16_224-cd65a155.pth\" to /root/.cache/torch/hub/checkpoints/deit_small_patch16_224-cd65a155.pth\n",
            " 41% 34.9M/84.2M [00:01<00:02, 23.1MB/s]Downloading: \"https://dl.fbaipublicfiles.com/deit/deit_small_patch16_224-cd65a155.pth\" to /root/.cache/torch/hub/checkpoints/deit_small_patch16_224-cd65a155.pth\n",
            " 49% 41.3M/84.2M [00:02<00:01, 22.6MB/s]Downloading: \"https://dl.fbaipublicfiles.com/deit/deit_small_patch16_224-cd65a155.pth\" to /root/.cache/torch/hub/checkpoints/deit_small_patch16_224-cd65a155.pth\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/deit/deit_small_patch16_224-cd65a155.pth\" to /root/.cache/torch/hub/checkpoints/deit_small_patch16_224-cd65a155.pth\n",
            " 49% 41.5M/84.2M [00:02<00:01, 28.7MB/s]Downloading: \"https://dl.fbaipublicfiles.com/deit/deit_small_patch16_224-cd65a155.pth\" to /root/.cache/torch/hub/checkpoints/deit_small_patch16_224-cd65a155.pth\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/deit/deit_small_patch16_224-cd65a155.pth\" to /root/.cache/torch/hub/checkpoints/deit_small_patch16_224-cd65a155.pth\n",
            "100% 84.2M/84.2M [00:04<00:00, 21.9MB/s]\n",
            "100% 84.2M/84.2M [00:04<00:00, 19.6MB/s]\n",
            "100% 84.2M/84.2M [00:04<00:00, 19.0MB/s]\n",
            "100% 84.2M/84.2M [00:04<00:00, 18.6MB/s]\n",
            " 90% 76.0M/84.2M [00:04<00:00, 17.8MB/s]\n",
            "100% 84.2M/84.2M [00:05<00:00, 16.7MB/s]\n",
            "100% 84.2M/84.2M [00:05<00:00, 15.8MB/s]\n",
            "100% 84.2M/84.2M [00:05<00:00, 15.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "!bash ./finetune.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python3 main.py --model deit_small_patch16_shrink_base --fuse_token --base_keep_rate 0.7 --eval --resume checkpoint --data-path \"/content/gdrive/.shortcut-targets-by-id/1FUYQ7eqJJam0F8pPkHaPpsm2LPDRriGk/ISIC2019bea_mel_nevus_limpo\" --output_dir /content/gdrive/MyDrive/IST/Thesis/Experiments/Experiment_123"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
